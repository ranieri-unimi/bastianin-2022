{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# and then we go to mario draghi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import datetime\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "from statsmodels.distributions.empirical_distribution import ECDF\n",
    "import math\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import pickle as pk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ad = pd.read_csv('datasets/1976-2020-president.csv')\n",
    "years = set(ad['year'])\n",
    "states = set(ad['state'])\n",
    "dflist = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states.remove('DISTRICT OF COLUMBIA')\n",
    "years.remove(1976)\n",
    "years.remove(1980)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### some function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def foofloat(x):\n",
    "    try:\n",
    "        return float(x)\n",
    "    except:\n",
    "        return np.NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bls_serial(series_id):\n",
    "  bsobj = bs(requests.post(\"https://data.bls.gov/pdq/SurveyOutputServlet\", {'series_id': series_id}).text)\n",
    "  return bsobj.findAll('table')[0].findAll('tr')[2].findAll('td')[0].text.strip().upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ecdf_inv(a, q): return sorted(a)[int(len(a) * q)]\n",
    "def count_elem(l): return {y:list(l).count(y) for y in set(l)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_percent(older, col_key, shift=0):\n",
    "    newer = []\n",
    "    for y in years:\n",
    "        for s in states:\n",
    "            try:\n",
    "                d = older.loc[y-shift, s, 'DEMOCRAT'][col_key]\n",
    "                r = older.loc[y-shift, s, 'REPUBLICAN'][col_key]\n",
    "                newer.append([int(y), s, 100*d/(d+r)]) # % share for each state\n",
    "            except KeyError as e:\n",
    "                pass\n",
    "    return pd.DataFrame(data=newer, columns=['year', 'state', col_key, ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_splatter(a, col_name): # from row-column to table-list\n",
    "    lst = []\n",
    "    for y in a.columns[2:]:\n",
    "        for index, row in a.iterrows():\n",
    "            lst.append([int(y), row['GeoName'].upper(), row[y], ])\n",
    "    \n",
    "    return pd.DataFrame(data=lst, columns=['year', 'state', col_name, ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def var42(df_res, colname, filename, old_colname, jump=1):\n",
    "    new_df = []\n",
    "    \n",
    "    df_res = df_res.set_index(['year', 'state'])\n",
    "    for y in years:\n",
    "        for s in states:\n",
    "            try:\n",
    "                new_df.append([y,s,] + [df_res.loc[y-i,s][old_colname] for i in range(0, 4, jump)])\n",
    "            except KeyError:\n",
    "                pass\n",
    "\n",
    "    new_df = pd.DataFrame(data=new_df, columns = ['year', 'state',] + [f'{colname}_{i}' for i in range(4//jump, 0, -1)])\n",
    "    new_df = new_df.sort_values(by=['year', 'state'])\n",
    "    new_df.to_csv(f'datasets-clean/{filename}.csv', index=False)\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beadiff(rowcol, colname, diff = True, shift=1):\n",
    "    difflist = []\n",
    "\n",
    "    for s in states:\n",
    "        tmp = rowcol.loc[(slice(None),s),:]\n",
    "        yyyy = list({i[0] for i in tmp.index})\n",
    "        yyyy.sort()\n",
    "        for y in yyyy[shift:]:\n",
    "            if diff:\n",
    "                q = rowcol.loc[(y,s),:][colname]/rowcol.loc[(int(y)-shift,s),:][colname]\n",
    "                q = (q - 1)*100\n",
    "            else:\n",
    "                q = rowcol.loc[(y,s),:][colname]\n",
    "            difflist.append([y, s, q])\n",
    "            \n",
    "    return  pd.DataFrame(data=difflist, columns=['year', 'state', colname])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def whore(df, yy=years, ss=states):\n",
    "    df = df.set_index(['year','state'])\n",
    "    x = []\n",
    "    for s in ss:\n",
    "        for y in yy:\n",
    "            try:\n",
    "                df.loc[(y,s),:]\n",
    "            except:\n",
    "                x.append((y,s))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### y_hat aka presitdent popular vote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_vote = pd.read_csv('datasets/1976-2020-president.csv')\n",
    "pop_vote = pop_vote[['year', 'state', 'party_simplified', 'candidatevotes', ]] # drop useless columns\n",
    "pop_vote = pop_vote.groupby(['year', 'state', 'party_simplified', ]).sum() # drop multiple candidate\n",
    "pop_vote = to_percent(pop_vote, 'candidatevotes')\n",
    "pop_vote = pop_vote.rename(columns={\"candidatevotes\": \"y_votes_percent\", })\n",
    "pop_vote = pop_vote.sort_values(by=['year', 'state'])\n",
    "pop_vote.to_csv('datasets-clean/popular-vote-y.csv', index=False)\n",
    "dflist.append(pop_vote)\n",
    "pop_vote"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GDP and friends"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It was necessary to generate an adjusted series of state GDP because of a change in BEAâ€™s estimation procedure from a Standard Industrial Classification (SIC) basis to a North American Industry Classification System (NAICS) basis in 1997.\n",
    "Data prior to 1997 were adjusted to avoid any erratic shifts in GDP that year.\n",
    "While the change to NAICS basis occurred in 1997, BEA also provides estimates under a SIC basis in that year.\n",
    "~~Our adjustment involved calculating the 1997 ratio of NAICS-based GDP to SIC-based GDP for each state, and multiplying it by SIC-based GDP in all years prior to 1997 to obtain our adjusted series of state-level GDP.~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdp_nom_97 = to_splatter(pd.read_csv('datasets/gdp-nominal-63-97.csv'), 'gdp_nom')\n",
    "gdp_nom_12 = to_splatter(pd.read_csv('datasets/gdp-nominal-97-20.csv'), 'gdp_nom')\n",
    "gdp_real_97 = to_splatter(pd.read_csv('datasets/gdp-real-77-97-chain-97.csv'), 'gdp_real')\n",
    "gdp_real_12 = to_splatter(pd.read_csv('datasets/gdp-real-97-20-chain-12.csv'), 'gdp_real')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdp_nom_97 = gdp_nom_97.set_index(['year', 'state'])\n",
    "gdp_nom_12 = gdp_nom_12.set_index(['year', 'state'])\n",
    "gdp_real_97 = gdp_real_97.set_index(['year', 'state'])\n",
    "gdp_real_12 = gdp_real_12.set_index(['year', 'state'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### price index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdp_def_97 = (gdp_nom_97['gdp_nom'] / gdp_real_97['gdp_real']).to_frame('gdp_def').dropna()\n",
    "gdp_def_12 = (gdp_nom_12['gdp_nom'] / gdp_real_12['gdp_real']).to_frame('gdp_def').dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdp_def = pd.concat([beadiff(gdp_def_12,'gdp_def'), beadiff(gdp_def_97,'gdp_def')])\n",
    "gdp_def = gdp_def.sort_values(by=['year', 'state'])\n",
    "gdp_def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def_index = var42(gdp_def, colname='def', filename='price-index', old_colname='gdp_def')\n",
    "dflist.append(def_index)\n",
    "def_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### gdp dummies and margin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdp_real_plain = gdp_real_12.copy()\n",
    "for y in range(1996, 1977, -1):\n",
    "    for s in sorted(states):\n",
    "        a = gdp_real_97.loc[(y,s),'gdp_real']\n",
    "        b = gdp_real_97.loc[(y+1,s),'gdp_real']\n",
    "        c = gdp_real_plain.loc[(y+1,s),'gdp_real']\n",
    "\n",
    "        gdp_real_plain.at[(y,s),'gdp_real'] = a*b/c\n",
    "\n",
    "gdp_real_plain = gdp_real_plain.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdp_real_var = pd.concat([beadiff(gdp_real_97,'gdp_real'), beadiff(gdp_real_12,'gdp_real')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdp_real_var_2 = pd.concat([beadiff(gdp_real_97,'gdp_real', shift=2), beadiff(gdp_real_12,'gdp_real', shift=2)])\n",
    "\n",
    "tmp = gdp_real_plain.set_index(['year','state'])\n",
    "tmp = tmp.loc[1998] / tmp.loc[1996]\n",
    "tmp['year'] = 1998\n",
    "\n",
    "gdp_real_var_2 = pd.concat([gdp_real_var_2, tmp.reset_index(), ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### z growth index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GDP_THRESHOLD = 3.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_yearly = gdp_real_var.copy()\n",
    "z_yearly.gdp_real = z_yearly.gdp_real.apply(lambda x : 1 if x > GDP_THRESHOLD else 0)\n",
    "\n",
    "growth_index = var42(z_yearly, colname='z', filename='z-growth-index', old_colname='gdp_real')\n",
    "dflist.append(growth_index)\n",
    "growth_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### g gdp index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdp_index = var42(gdp_real_var_2, colname='gdp_mt', filename='gdp-growth-index', old_colname='gdp_real', jump=2)\n",
    "dflist.append(gdp_index)\n",
    "gdp_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "gdp_index['gdp_34'] = (gdp_index['gdp_3']+gdp_index['gdp_3'])/2\n",
    "gdp_index['gdp_12'] = (gdp_index['gdp_1']+gdp_index['gdp_2'])/2\n",
    "\n",
    "del gdp_index['gdp_1']\n",
    "del gdp_index['gdp_2']\n",
    "del gdp_index['gdp_3']\n",
    "del gdp_index['gdp_4']\n",
    "#'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### incumbent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incumbent = pd.read_csv('datasets/incumbent-4president-76-20.csv', sep=';')\n",
    "\n",
    "tmp = pd.DataFrame(data=[[y,s] for y in years for s in states], columns=['year', 'state'])\n",
    "incumbent = pd.merge(tmp, incumbent, how='inner', left_on='year', right_on='year')\n",
    "incumbent = incumbent.sort_values(by=['year', 'state'])\n",
    "incumbent.to_csv('datasets-clean/incumbent-longitudinal-replication.csv', index=False)\n",
    "dflist.append(incumbent)\n",
    "incumbent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### house dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "house_vote = pd.read_csv('datasets/1976-2020-house-utf8.csv')\n",
    "house_vote = house_vote[['year', 'state', 'party', 'candidatevotes', ]]\n",
    "house_vote = house_vote.groupby(['year', 'state', 'party', ]).sum()\n",
    "house_vote = to_percent(house_vote, 'candidatevotes', shift=2)\n",
    "house_vote['candidatevotes'] = house_vote['candidatevotes'].apply(lambda x: -1 if x < 50 else 1)\n",
    "house_vote = house_vote.rename(columns={'candidatevotes':'house_midterm'})\n",
    "house_vote = pd.concat([house_vote, pd.read_csv('datasets/midterm-fixed.csv')])\n",
    "house_vote.state = house_vote.state.apply(lambda x : x.upper())\n",
    "house_vote = house_vote.sort_values(by=['year', 'state'])\n",
    "house_vote.to_csv('datasets-clean/incumbent-house-rep.csv', index=False)\n",
    "dflist.append(house_vote)\n",
    "house_vote"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### personal income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inc_cap = to_splatter(pd.read_csv('datasets/personal-income-per-capita-72-20.csv'), 'avg_inc')\n",
    "#inc_cap.avg_inc = inc_cap.avg_inc.apply(lambda x: math.log(x))\n",
    "inc_cap = inc_cap.set_index(['year', 'state'])\n",
    "inc_cap = beadiff(inc_cap, 'avg_inc', False)\n",
    "inc_cap = var42(inc_cap, 'avg_inc', 'income-index', 'avg_inc')\n",
    "dflist.append(inc_cap)\n",
    "inc_cap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### unenployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unn = pd.read_csv('datasets/unemployment-76-21-percent.csv')\n",
    "furi = 'datasets-clean/serial-id-bsl.pkl'\n",
    "\n",
    "if False:\n",
    "    sd = dict()\n",
    "    for s in set([*unn['Series ID'], *nunn['Series ID']]):\n",
    "        try:\n",
    "            sd[s] = bls_serial(s)\n",
    "        except IndexError:\n",
    "            sd[s] = f'BADASS_{s}'\n",
    "    pk.dump(sd, open(furi, 'wb'))\n",
    "else:\n",
    "    sd = pk.load(open(furi, 'rb'))\n",
    "\n",
    "unn = unn.rename(columns={\n",
    "    \"Series ID\": \"state\",\n",
    "    \"Year\": \"year\",\n",
    "    \"Value\": \"unemp\",\n",
    "    \"Period\": \"month\",\n",
    "    })\n",
    "\n",
    "# transform\n",
    "unn.unemp = unn.unemp.apply(foofloat).astype(float)\n",
    "unn.state = unn.state.map(sd)\n",
    "unn.month = unn.month.apply(lambda x: x.split('M')[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glue = pd.read_csv('datasets/unemployment-rate-us-country-47-21.csv')\n",
    "glue['year'] = glue.DATE.apply(lambda x: x.split('-')[0])\n",
    "glue['month'] = glue.DATE.apply(lambda x: x.split('-')[1])\n",
    "glue = glue.set_index(['year','month'])\n",
    "\n",
    "for i in unn.index:\n",
    "    unn.at[i, \"unemp\"] = glue.at[(unn.at[i, \"year\"], unn.at[i, \"month\"]), 'UNRATE'] if unn.at[i, \"unemp\"] == np.NaN else unn.at[i, \"unemp\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dmp = unn.set_index(['year','month','state'])\n",
    "\n",
    "tmp = []\n",
    "for y in years:\n",
    "    for s in states:\n",
    "        m2 = (dmp.loc[(y, '10', s), 'unemp'] / dmp.loc[(y-2, '11', s), 'unemp'])*100 - 100\n",
    "        m1 = (dmp.loc[(y-2, '10', s), 'unemp'] / dmp.loc[(y-4, '01', s), 'unemp'])*100 - 100\n",
    "        tmp.append([y,s,m1,m2])\n",
    "        \n",
    "mid_unem = pd.DataFrame(data=tmp, columns=['year', 'state', 'unemp_mt_1', 'unemp_mt_2'])\n",
    "dflist.append(mid_unem)\n",
    "mid_unem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "tmp = []\n",
    "for y in years:\n",
    "    for s in states:\n",
    "        m2 = unn[unn.year >= y-1][unn.year <= y][unn.state == s].unemp.median()\n",
    "        m1 = unn[unn.year >= y-3][unn.year <= y-2][unn.state == s].unemp.median()\n",
    "        tmp.append([y,s,m1,m2])\n",
    "mid_unem = pd.DataFrame(data=tmp, columns=['year', 'state', 'unemp_12', 'unemp_34'])\n",
    "dflist.append(mid_unem)\n",
    "mid_unem\n",
    "#'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "unn = var42(unn, 'unemp', 'unemployment-index', 'unemp')\n",
    "dflist.append(unn)\n",
    "unn\n",
    "#'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### merging features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=[[y,s] for y in years for s in states], columns=['year', 'state'])\n",
    "for d in dflist:\n",
    "    df = df.merge(d, how='inner', left_on=['year','state'], right_on=['year','state'])\n",
    "\n",
    "df = df.sort_values(by=['year', 'state'])\n",
    "df.to_csv('datasets-clean/xxx-final-dataset.csv', index=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in dflist:\n",
    "    w = whore(d.set_index(['year', 'state']))\n",
    "    if len(w):\n",
    "        print('-+'*30)\n",
    "        print(d.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0/0\n",
    "# chernobyl zone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "exp fail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdp_boot = gdp_real.copy()\n",
    "gdp_exp = gdp_boot.set_index(['year', 'state'])\n",
    "for s in states:\n",
    "    print(gdp_exp.loc[(slice(None),s),:].gdp_real.apply(lambda x : math.exp((x - gdp_exp.gdp_real.mean())/ math.sqrt(gdp_exp.gdp_real.var()))))\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "us stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdp_us = pd.read_csv('datasets/gdp-nomina-47-20-chain-12.csv')\n",
    "gdp_us.DATE = gdp_us.DATE.apply(lambda x: int(str(x).split('-')[0]))\n",
    "s = gdp_us[gdp_us.DATE > 1975].GDPC1_PC1\n",
    "s.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecdf = ECDF(s)\n",
    "ecdf(2.8)\n",
    "\n",
    "qnt = 0.67\n",
    "std_err = np.sqrt(s.var())/2\n",
    "ecdf_inv(s, qnt), len(s)*(1-qnt), std_err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### house"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "house_vote = pd.read_csv('datasets/1976-2020-house-utf8.csv')\n",
    "house_vote = house_vote[['year', 'state', 'party', 'candidatevotes', ]]\n",
    "house_vote = house_vote.groupby(['year', 'state', 'party', ]).sum()\n",
    "house_vote = to_percent(house_vote, 'candidatevotes')\n",
    "house_vote = house_vote.rename(columns={\"candidatevotes\": \"houserep_votes_percent\", })\n",
    "#'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### gasoline and friends + approval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gas = pd.read_csv('datasets/gasoline-93-21.csv')\n",
    "gas.date = gas.date.apply(lambda x: time.mktime(datetime.datetime.strptime(x,\"%m/%d/%Y\").timetuple()))\n",
    "gas.date = gas.date.apply(lambda x: datetime.datetime.fromtimestamp(int(x)))\n",
    "gas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### houses prices and rent + personal income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('datasets/house-chain-00.csv', 'rt')\n",
    "lines = f.readlines()\n",
    "houses = [[i.strip() for i in l.split(sep = '$') ] for l in lines ]\n",
    "houses = pd.DataFrame(data=houses, columns=['state', 2000, 1990, 1980, 1970, 1960, 1950, 1940 ])\n",
    "houses.head()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
